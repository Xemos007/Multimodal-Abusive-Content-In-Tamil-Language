{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36197c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Single Video (1706, 224, 224, 3)\n",
      "{0: 0}\n",
      "(1706, 2048)\n",
      "(745, 2048)\n",
      "(909, 2048)\n",
      "(1895, 2048)\n",
      "(1745, 2048)\n",
      "(2203, 2048)\n",
      "(1664, 2048)\n",
      "(1846, 2048)\n",
      "(1790, 2048)\n",
      "(1568, 2048)\n",
      "(1575, 2048)\n",
      "(1586, 2048)\n",
      "(1368, 2048)\n",
      "(1564, 2048)\n",
      "(1801, 2048)\n",
      "(1683, 2048)\n",
      "(1630, 2048)\n",
      "(1711, 2048)\n",
      "(2113, 2048)\n",
      "(1576, 2048)\n",
      "(1530, 2048)\n",
      "(2004, 2048)\n",
      "(1479, 2048)\n",
      "(1161, 2048)\n",
      "(2126, 2048)\n",
      "(1507, 2048)\n",
      "(2186, 2048)\n",
      "(1570, 2048)\n",
      "(1642, 2048)\n",
      "(1607, 2048)\n",
      "(1383, 2048)\n",
      "(1838, 2048)\n",
      "(1739, 2048)\n",
      "(1056, 2048)\n",
      "(1627, 2048)\n",
      "(1520, 2048)\n",
      "(809, 2048)\n",
      "(762, 2048)\n",
      "(1576, 2048)\n",
      "(873, 2048)\n",
      "(1216, 2048)\n",
      "(1047, 2048)\n",
      "(835, 2048)\n",
      "(1505, 2048)\n",
      "(626, 2048)\n",
      "(1728, 2048)\n",
      "(1476, 2048)\n",
      "(1805, 2048)\n",
      "(1063, 2048)\n",
      "(774, 2048)\n",
      "(1448, 2048)\n",
      "(1296, 2048)\n",
      "(1416, 2048)\n",
      "(900, 2048)\n",
      "(1718, 2048)\n",
      "(900, 2048)\n",
      "(900, 2048)\n",
      "(1135, 2048)\n",
      "(1233, 2048)\n",
      "(897, 2048)\n",
      "(1499, 2048)\n",
      "(1417, 2048)\n",
      "(1516, 2048)\n",
      "(1556, 2048)\n",
      "(1037, 2048)\n",
      "(1366, 2048)\n",
      "(1218, 2048)\n",
      "(700, 2048)\n",
      "(1513, 2048)\n",
      "(1197, 2048)\n",
      "(1336, 2048)\n",
      "(1115, 2048)\n",
      "(638, 2048)\n",
      "(1700, 2048)\n",
      "(2588, 2048)\n",
      "(1783, 2048)\n",
      "(1820, 2048)\n",
      "(1688, 2048)\n",
      "(1435, 2048)\n",
      "(2562, 2048)\n",
      "(1352, 2048)\n",
      "(1036, 2048)\n",
      "(1114, 2048)\n",
      "(939, 2048)\n",
      "(1115, 2048)\n",
      "(1273, 2048)\n",
      "(1408, 2048)\n",
      "(1584, 2048)\n",
      "Shape of Video Features (72,)\n",
      "Maximum number of Frames 2203\n",
      "Average Number of Frames 1417.513888888889\n",
      "Shape of Video Features for Test data: (16,)\n",
      "Maximum number of Frames for Test data: 2588\n",
      "Average Number of Frames for Test data: 1502.1875\n",
      "<=========================END OF DATA PREPROCESSING (Total Time Taken: 13.482004670302073 Minutes) =================================>\n"
     ]
    }
   ],
   "source": [
    "#Importing the required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "random.seed(7)\n",
    "import cv2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "#Required Hyperparameter\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "NUM_FEATURES = 2048\n",
    "\n",
    "#Reading the videos\n",
    "dataset_path = \"D:/CSE(AI)/SEM-7/Mini-Project/Data/Videos/\"\n",
    "def load_video(path,resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)\n",
    "videos_train = []\n",
    "labels_train = []\n",
    "\n",
    "test_ind = [21, 61, 65, 43, 55, 22, 50, 35, 50, 33, 64, 64, 82, 23, 31, 60, 1, 3]\n",
    "videos_test = []\n",
    "labels_test = []\n",
    "cntr = 0\n",
    "for folder in os.listdir(dataset_path):\n",
    "  for f in os.listdir(dataset_path+folder):\n",
    "    video_path = dataset_path+folder+\"/\"+f\n",
    "    if(cntr in test_ind):\n",
    "        videos_test.append(load_video(video_path))\n",
    "        labels_test.append(folder)\n",
    "    else:\n",
    "        videos_train.append(load_video(video_path))\n",
    "        labels_train.append(folder)\n",
    "    cntr += 1\n",
    "\n",
    "print(\"Shape of Single Video\",np.shape(videos_train[0]))    \n",
    "\n",
    "le = LabelEncoder()\n",
    "for i in range(len(labels_train)):\n",
    "    if(labels_train[i]):\n",
    "        labels_train[i] = 0\n",
    "    else:\n",
    "        labels_train[i] = 1\n",
    "y_transform = le.fit_transform(labels_train)\n",
    "y_cat_train = np_utils.to_categorical(y_transform)\n",
    "\n",
    "for i in range(len(labels_test)):\n",
    "    if(labels_test[i]):\n",
    "        labels_test[i] = 0\n",
    "    else:\n",
    "        labels_test[i] = 1\n",
    "y_transform = le.fit_transform(labels_test)\n",
    "y_cat_test = np_utils.to_categorical(y_transform)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "\n",
    "#feature_extraction\n",
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.inception_v3.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"max\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "    \n",
    "feature_extractor = build_feature_extractor()\n",
    "vid_features_train = []\n",
    "n_frames_train = []\n",
    "for i in videos_train:\n",
    "    temp=feature_extractor.predict(i)\n",
    "    n_frames_train.append(len(temp))\n",
    "    vid_features_train.append(temp)\n",
    "    print(np.shape(temp))\n",
    "\n",
    "vid_features_test = []\n",
    "n_frames_test = []\n",
    "for i in videos_test:\n",
    "    temp=feature_extractor.predict(i)\n",
    "    n_frames_test.append(len(temp))\n",
    "    vid_features_test.append(temp)\n",
    "    print(np.shape(temp))\n",
    "  \n",
    "print(\"Shape of Video Features\",np.shape(vid_features_train))\n",
    "print(\"Maximum number of Frames\",max(n_frames_train))\n",
    "print(\"Average Number of Frames\",np.mean(n_frames_train))\n",
    "\n",
    "print(\"Shape of Video Features for Test data:\",np.shape(vid_features_test))\n",
    "print(\"Maximum number of Frames for Test data:\",max(n_frames_test))\n",
    "print(\"Average Number of Frames for Test data:\",np.mean(n_frames_test))\n",
    "\n",
    "np.save(\"no_pad_data_train.npy\",np.array(vid_features_train))\n",
    "np.save(\"no_pad_labels_train.npy\",np.array(y_cat_train))\n",
    "np.save(\"no_pad_data_test.npy\",np.array(vid_features_test))\n",
    "np.save(\"no_pad_labels_test.npy\",np.array(y_cat_test))\n",
    "\n",
    "print(\"<=========================END OF DATA PREPROCESSING (Total Time Taken: {} Minutes) =================================>\".format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200377c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
