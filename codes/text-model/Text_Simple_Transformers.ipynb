{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import timeit\n",
    "import warnings\n",
    "import string\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "import emoji\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tkinter import ttk\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    #text = re.sub(\"[^a-zA-Z]\", \" \",text)\n",
    "    #text = re.sub(\"[0-9]\", \" \",text)\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    text = text.lower()\n",
    "    text = (re.sub(' +',' ',text)).strip()\n",
    "    text = emoji.get_emoji_regexp().sub(\"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backto(arr):\n",
    "    A=[]\n",
    "    for i in arr:\n",
    "        A.append(np.argmax(i))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(y_test,y_pred):\n",
    "    accuracy = accuracy_score(y_test,y_pred) # Accuracy of prediction\n",
    "    conf_mat = confusion_matrix(y_test, y_pred) # Confusion matrix\n",
    "    precision = precision_score(y_test, y_pred, average='macro') # Precision\n",
    "    recall = recall_score(y_test, y_pred, average='macro') # Recall\n",
    "    f1 = f1_score(y_test, y_pred, average='macro') # F1-score\n",
    "    evaluation = [accuracy, conf_mat, precision, recall, f1]\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_vals(df_col):\n",
    "    A=[]\n",
    "    for i in df_col:\n",
    "        t = [0]*max(np.unique(df_col)+1)\n",
    "        t[i]=1\n",
    "        A.append(t)\n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0], [0, 0, 1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_vals([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(path, n, label):\n",
    "  x = []\n",
    "  T = \"\"\n",
    "  with open(str(path),encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for e in lines:\n",
    "      T = T + e\n",
    "  x.append(T)\n",
    "  L = np.zeros(len(x))\n",
    "  if(label == 1):\n",
    "    L = np.ones(len(x))\n",
    "  return x\n",
    "\n",
    "def load_len(path, n, label):\n",
    "  x = []\n",
    "  T = \"\"\n",
    "  with open(str(path),encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for e in lines:\n",
    "      T = T + e\n",
    "  x.append(T)\n",
    "  L = np.zeros(len(x))\n",
    "  if(label == 1):\n",
    "    L = np.ones(len(x))\n",
    "  return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "p = 'D:/Co/Sem7/Prj/MiniProj/Dataset/TEST/'\n",
    "N = [9, 9]\n",
    "L = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abusive-1.txt', 'Abusive-11.txt', 'Abusive-14.txt', 'Abusive-19.txt', 'Abusive-23.txt', 'Abusive-28.txt', 'Abusive-35.txt', 'Abusive-6.txt', 'Abusive-8.txt', 'Non-Abusive-1.txt', 'Non-Abusive-11.txt', 'Non-Abusive-13.txt', 'Non-Abusive-19.txt', 'Non-Abusive-23.txt', 'Non-Abusive-28.txt', 'Non-Abusive-32.txt', 'Non-Abusive-5.txt', 'Non-Abusive-8.txt']\n"
     ]
    }
   ],
   "source": [
    "ffiles = []\n",
    "\n",
    "for root, dirs, files in os.walk(p):\n",
    "    for file in files:\n",
    "        # check if the file name contains the word 'hello'\n",
    "        # add the file name to the list\n",
    "        ffiles.append(file)\n",
    "            \n",
    "print(ffiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Co/Sem7/Prj/MiniProj/Dataset/TEST/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abusive-1.txt', 'Abusive-11.txt', 'Abusive-14.txt', 'Abusive-19.txt', 'Abusive-23.txt', 'Abusive-28.txt', 'Abusive-35.txt', 'Abusive-6.txt', 'Abusive-8.txt', 'Non-Abusive-1.txt', 'Non-Abusive-11.txt', 'Non-Abusive-13.txt', 'Non-Abusive-19.txt', 'Non-Abusive-23.txt', 'Non-Abusive-28.txt', 'Non-Abusive-32.txt', 'Non-Abusive-5.txt', 'Non-Abusive-8.txt']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import WindowsPath\n",
    "\n",
    "#fflies = [p + element  for element in ffiles]\n",
    "print(ffiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Text_ab = []\n",
    "Text_nab = []\n",
    "Lbl_ab = []\n",
    "Lbl_nab = []\n",
    "\n",
    "for i in range(9):\n",
    "    Text_ab.append((load_text( p + ffiles[i] ,N[0], 0)))\n",
    "    Lbl_ab.append(load_len( p + ffiles[i] ,N[0], 0))\n",
    "    Text_nab.append(load_text( p + ffiles[i+9] ,N[1], 1))\n",
    "    Lbl_nab.append(load_len( p + ffiles[i+9] ,N[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['அஞ்சு வருஷம் உங்க பவர் காமிச்சீங்களே என்ன ஆட்டம் போட்டீங்க எடிமகே  சுண்ணிக்கே எங்க தளபதி அத தடுக்கத்தாண்டா வராரு அவுர மட்டும் அழிக்கணும்னு நினைச்ச முடியவே முடியாது நீ அதுக்கு தகுதியே கிடையாது எடிமகே ஒ சுண்ணிக்கே ஒ நீ அதுக்கு தகுதியே கிடையாது என் தளபதி தான் இந்த நாட்டையே இந்த நாட்டையே நல்லவிதமா மாத்துறது எங்க தளபதி மட்டும்தான் நீ அந்த அஞ்சு வருஷம் என்ன பண்ணமுடியும் இந்த மக்களுக்காக இந்த மக்கள் என்ன பண்ணப்போறாய்ங்க அந்த தைரியத்தில தானே நீக்க இப்படி ஆடுறிங்க இந்த சர்க்கார் படம் வந்ததுல தாண்ட தெரியுது உங்க ஊழல் புண்ட என்னடா புண்டைகளா சிரிப்புத்தாண்டா வருது உங்கள பாத்த உங்களப்பத்தி பேசுனாலே சிரிப்பு புண்ட தாண்ட வருது கோவா புண்டைய வருது ஜோக்கர் புண்டடா நீங்கல்லாம் இப்படி பேசுறாங்களே அவமான புண்டையா இல்லையா     '],\n",
       " ['... கிட்ட பசங்க கவனமா இருக்கனும். ஒரு கட்டத்துல டீசென்ட் ஆஹ் விலகி போகாம, பெரிய சண்டை ஆஹ் போடு கெளம்பனும் னு நெனச்சீங்கனா. இந்த எஸ்பிஎரிஎன்ஸ் ஆனா ஆண்ட்டிங்க உங்க வாழ்க்கை ஆஹ் வே காலி பன்னிடுவாங்க. நீங்க வேல பண்ற எடத்துல கண்ட படி மெயில் அனுப்புறது தொடங்கி, உங்க பேமிலி ரெளடிவ்ஸ் கு உங்கள போட்டு குடுக்குற வரைக்கும் சிறப்பா செஞ்சிடுவாங்க. சோ ஒரு முறை கு நூறு முறை நல்லா யோசிச்சிக்கோங்க. ஆண்ட்டி ஆஹ் ரூட் விடுறது சேரி ஆஹ் இல்லையா னு. ஒகே பிரிஎண்ட்ஸ் அவளோ தான் இந்த வீடியோ மீண்டும் ஒரு சுவாரஸ்யமான வீடியோ ஓட அடுத்த செக்மென்ட் ல சந்திக்கலாம்.  '],\n",
       " ['என் பக்கத்துலயே இருக்க, ஓத்தா என் பக்கத்துல இருந்த நீ இந்நேரத்துக்கு உயிரோட இருக்க மாட்ட டா பாடு. உன் பூலு இருக்கு ல அப்படியே ரெண்டா கிழிச்சி இருப்பேன், கிழிச்சி ஓத்தா உன் சூத்து கீது எல்லாம் ஓத்தா உன்னையே ரெண்டா கிழிச்சி இருப்பேன். என்ன சும்மா இங்கிலிஷ் ல, நா படிக்கல உண்மை உண்மை ஆஹ் சொல்லனும் ந பத்தாவது தான் படிச்சி இருக்கேன். நா பேசுறது எல்லாம் நான் ஆஹ் காதுகுடத்து தான். ஒகே? சோ ஸ்டாப். நா வந்து திருப்பி திருப்பி திருப்பி திருப்பி திருப்பி உங்க கிட்ட ல ஓத்தா காத்திடு இருக்கானு ன்ற அவசிய புண்டை எனக்கு கிடையாது. ஐபி யு டூ தட் அகைன் ஐ வில் செறிவுசலை ஐ வில் புட் மோர் போஸ்டல் அண்ட் மோர் ளைவ்ஸ் ஒன்லி போர் யு லைக் யு அசோலஸ். லுக் எவேர்யோனே ஐஸ் பாஸிங் சோ மச் ப்ரோப்லேம்ஸ் இன் தெயர் லைப். எவெரிஒன் ஹாஸ் தெயர் ஓவ்ன் ஷிட்ஸ் டு கிலீர். ஸ்டாப் புள்ளயிங் தேம். ஸ்டாப் டூ திஸ் அகைன் அண்ட் அகைன். பை செல்லம் ஆஹ் ஓத்தா, போடா பாடு, வண்டா பை சொல்றதுக்கு. வா குடு வா ஓத்தா இந்த ஆணி செருப்பு வெச்சி இருக்கேன் அதுல பொய் உம்மா குடு, உன் பூலை வெச்சி தேயி, பாடு.'],\n",
       " ['ஏன் டா நீயே உன்ன ரேப் பங்கிட்டு இருக்கையே. நா சொன்னே மச்சா இது ஒரு சீன் காக நா ரீஹர்ஸ் பண்ணீட்டு இருக்கேன் அந்த பொண்ணு அத ஒதுக்களை னு மட்டும் தா லவ் அ ஒதுக்களை நா மட்டும் தா அதெல்ல நடக்கும் அப்டினு நா சொல்லி இருந்தேன். அப்டி ரேப் பண்ண முடியலைன்னா இ வில் மேக் அ மீ ம் அவுட் ஆப் ஹேர். இ அம் ஸ்லுச்சிங் ஹேர் தட்ஷஹௌ இட் ஒர்க்ஸ் அண்ட் ஷி பால் இந்த லவ். டெல் அஸ் அபௌட் தி மீ ம் செரிஸ் யு ஆர் பிளானிங் போர் வெரி லாங் பீரியட் ஆப் டைம். யாரு கிட்டயும் சொல்லாம ஒன்னு பண்றீங்களாமே அது என்னனு சொல்லி ஷேர் பணிகொங்க பட் ஆடின்ஸ் பாத்துட்டு இருக்குறவங்களாம் இது ஒரு புதுசா ஆகுமெண்ட்டட் ஆ ட்ரை பேணுவோம் எல்லாரும் வந்து கண்ண மூடுங்க. இட்ஸ் அ ஆட்டோ பயோ கிராபி பிக்சன் காமலக்கண்ணன் காமாச்சி அப்டினு ரெண்டு பேரோட கதை அ எழுதிட்டு இருக்கேன். மீ ம் கிரேட்டர்ஸ் சோசியல் மீ ம் அர்ஷ் இவங்க ரெண்டுபேருமே மீ ம் பேஜ் ல கமெண்ட் ல மீட் பண்றங்க. தே கனெக்ட் அக் ராஸ் கிரிங்கே அக் ராஸ் விவசாயி டிக்ஸ் , அக் ராஸ் துப்பட்டா போடுங்க தோழிஸ் பட் லெகின்ஸ் போடாதீங்க கான்செப்ட் இந்த மாறி விஷயங்கள் ல. வி ஈவென்ச்சுவல்லி மீட் அப் டு பைன்ட் போது ஆப் தெம் ஆர் கைஸ் பட் நன் ஆப் தெம் ஆர் கெய்ஷ். '],\n",
       " ['லைப் ல ட்ரிப் ஆகி சிறுச்சவங்கள விட வீட் கிடைக்காம அழுத்தவங்க தா ஜாஸ்த்தீ \\nஐ நோ தி பெயின் ஆப் தி பெலியர்ஸ் பிரண்ட்ஸ் ஒவொரு தடவ அரியார் வைக்கும்போது ரிசல்ட் பைல் னு போடும்போது தீபார் னு போடும்போது\\nஓத்தா இதுயென்ன சப்ஜெக்ட் னு பேறே தெரியாத சப்ஜெக்ட் ல பைல் ஆகும்போது வர அந்த பெயின் காப் சிரப் குடுச்சாலும் போகாதுனு \\nஎனக்கு தெரியும் இப்படி நீ எவளோ தோத்து இருந்தாலும் நீ மட்டும் விட்டு குடுத்துடாத உண்மையான தோல்வி எப்ப தெரியுமா நா தொட்டுட்டேன் னு\\n நானே எப்ப டிக்கலர் பணிக்குறேனோ அப்பத்தா இன்னும் நாலு வருஷம் அரியார் எழுத்து ஓத்தா  யாரு கேப்பா \\nவீக்கான சப்ஜெக்ட் கு டியூஷன் பொய் டீச்சர் அ கரீக்ட் பண்ணு ஒம்மலே யாரு தடுப்பை \\nஇந்த உலகம் உன்ன 1000 தடவ தோக்கடிக்கலாம் இந்த சமூகம் உன்ன லச்ச தடவ தோக்கடிக்கலாம் \\nயாரு தொகடுசலும் போடா புண்டை அப்டினு சொல்லி வீட் அடுச்சு போயிட்டே இரு '],\n",
       " ['ஏற்கனவே சந்தோஷ்சுப்ரமணி படத்துல வர காசினி மாறி திரியுறாளே. இவன் பண்ற மொக்க காமெடி குலாம் சிரிக்குறளே னு நாம பரிதாபம் பட்டோம்னா நம்மள பொறாமை படுறான் னு சொல்றளுக. அவங்கள சாதாரணமா சொல்லிட முடியாது அவன் நாளாவே ஓல ஓப்பான். அவனுக்கு விஷபேர் இல்லனாலும் கூட னால துல்லியமா அர்த்தம் சொல்லிகுடுப்பான் எந்த அளவுக்கு துல்லியமா நா சில நேரம் புறநானுறு சிலப்பதிகாரம் வெரிகுட் கூட பொய் கோட் பனி அர்த்தம் சொல்லி குடுப்பான். நாம கோவத்துல ஏதாவது ரெண்டு கேட்ட வார்த்தை போடு திட்டிட்டேன் நா இது மோதலை அவனுக்கு போகும் அவன் தனி தனி வார்த்தைகளா பிரிச்சுடுவான் அப்பறோம் ஒரு ஒரு வார்த்தைக்கும் துல்லியமா விளக்கிடுவான். ஒடனே அவளு உன் மனசுல நீ என்ன இப்டிதா நினச்சுட்டு இருந்தாயா அப்டினு நாம கிட்ட கேப்பா. ஏன்டா சுன்னிகளா கோவத்துல ஏதாச்சும் ரெண்டு எது எதுனா அது கூவம் மட்டும் தா வார்த்தைக்கு அர்த்தம் கண்டு பிடுச்சுட்டு இருந்த நாம என்ன பண்றது னு கேட்டா அவ அதையும் பொறாமை னு நினச்சுடுவா னு சொல்லிட்டு நாம அப்டியே போயிடுவோம் இந்த எளவுக்கு பிஎப்எப் னு பெரு வேற நாம கடைசி வர பிரண்டு னு சொல்லி கேப்ஷன் வேற வைப்பாங்க ஏன் பிரெண்டு னு சொல்லிட்டு நீயே அவளை வச்சு வாழறா கூதி னு நாம கிளம்புனா நம்மள கெட்டவன்ராலுக. '],\n",
       " ['உங்களுடைய கோவம் வந்து எனக்கு புரியுது எப்படி ஒரு போன ௨௫ வருஷம் வலது இன்னோருத்தவன் போட விடுறது அப்படின்ற கோவம் வந்து உங்க கேள்வி இருந்தது. பேசாம நீங்களே போட்டுருங்களே. பங்கு சூப்பர் பங்கு. எனக்கும் உங்க கிட்ட பேசுனது ரொம்ப சந்தோசம் இனிமே உங்க பேர் என்னனு கேட்ட இன்ஸஸ் சுதன் னு சொல்லணும் அடுத்த தடவ இன்ஸஸ் சுதன் னு சொல்லுங்க நா கரெக்ட் அ ஐடென்டிபிய பண்ணிடுவேன். இவானா மாறியே எல்லாரும் இன்ஸஸ் அ இறந்துட்டாங்க அப்டினா காதலும் இருக்காது காதல் சார்ந்து வர ஆணவ கொலையும் இருக்காது. '],\n",
       " ['இன்ஸ்டால யூடூப்ல செலிபிரிட்டி யாரு நல்லவங்க நீங்களே சொல்லுங்க சாதன ஆண்ட்டியா சூரிய ஆண்ட்டியா இல்ல ஷீலா அக்காவா இல்ல திவ்யாவா நீக்க கமெண்ட் பண்ணுங்க பாப்போம் யாருமே சொல்ல முடியாது இங்க ஐட்டம் அங்க ஐட்டம் சீ எங்க பாத்தாலும் ஐட்டம் ஆஹ் அலஞ்சுகிட்டு ஜி பி முத்து அந்த ஆளு ஒரு ஆம்பள ஐட்டம் அரிச்சலவள என்னக்கு இதெல்லாம் சுத்தமா பிடிக்காது திவ்யா என்னடானா எல்லாரையும் கட்டிபிடிச்சுக்கிட்டு ரேப் பண்ணிக்கிட்டு இதெல்லாம் ஒரு பொல்லப்பா ஒரு பொண்ணு தான நீ உனக்கு கற்புனு ஒன்னு இருக்காது கடவுள் படைக்கல உன்னக்கு கற்புன்றது என் இப்படிலாம் பண்ற எல்லாத்தையும் கடவுள் பாத்துட்டு தான் இருக்காரு தயவுசெஞ்சு திருந்தி வாழுங்க எல்லாரும்'],\n",
       " ['கோமா உண்ட ஓத்தா புண்டை கண்டறி ஒதால ல கு கோமா உண்ட நா  உன்கிட்ட நீ எவன் கிட்ட ந சொல்லு போ, போ பச்சகாரா சுண்ட, பச்சகாரா கோமா, ஆ மூடுற ஒதாலகா ஏகா அட மூடுறா ஓத்தா புண்டை அட வாடா ']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.]),\n",
       " array([1.]),\n",
       " array([1.]),\n",
       " array([1.]),\n",
       " array([1.]),\n",
       " array([1.]),\n",
       " array([1.]),\n",
       " array([1.]),\n",
       " array([1.])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lbl_nab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = Text_nab + Text_ab\n",
    "Lbl = np.concatenate((Lbl_nab, Lbl_ab), axis = 0)\n",
    "len(Text), len(Lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[Text, Lbl], index=[\"text\", \"label\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('prj_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "p = 'D:/Co/Sem7/Prj/MiniProj/Dataset/TRAIN/'\n",
    "N = [32, 38]\n",
    "L = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abusive-10.txt', 'Abusive-12.txt', 'Abusive-13.txt', 'Abusive-15.txt', 'Abusive-16.txt', 'Abusive-17.txt', 'Abusive-18.txt', 'Abusive-2.txt', 'Abusive-20.txt', 'Abusive-21.txt', 'Abusive-22.txt', 'Abusive-24.txt', 'Abusive-25.txt', 'Abusive-26.txt', 'Abusive-27.txt', 'Abusive-29.txt', 'Abusive-3.txt', 'Abusive-30.txt', 'Abusive-31.txt', 'Abusive-32.txt', 'Abusive-33.txt', 'Abusive-34.txt', 'Abusive-36.txt', 'Abusive-37.txt', 'Abusive-38.txt', 'Abusive-39.txt', 'Abusive-4.txt', 'Abusive-40.txt', 'Abusive-41.txt', 'Abusive-42.txt', 'Abusive-43.txt', 'Abusive-44.txt', 'Abusive-45.txt', 'Abusive-46.txt', 'Abusive-47.txt', 'Abusive-5.txt', 'Abusive-7.txt', 'Abusive-9.txt', 'Non-Abusive-10.txt', 'Non-Abusive-12.txt', 'Non-Abusive-14.txt', 'Non-Abusive-15.txt', 'Non-Abusive-16.txt', 'Non-Abusive-17.txt', 'Non-Abusive-18.txt', 'Non-Abusive-2.txt', 'Non-Abusive-20.txt', 'Non-Abusive-21.txt', 'Non-Abusive-22.txt', 'Non-Abusive-24.txt', 'Non-Abusive-25.txt', 'Non-Abusive-26.txt', 'Non-Abusive-27.txt', 'Non-Abusive-29.txt', 'Non-Abusive-3.txt', 'Non-Abusive-30.txt', 'Non-Abusive-31.txt', 'Non-Abusive-33.txt', 'Non-Abusive-34.txt', 'Non-Abusive-35.txt', 'Non-Abusive-36.txt', 'Non-Abusive-37.txt', 'Non-Abusive-38.txt', 'Non-Abusive-39.txt', 'Non-Abusive-4.txt', 'Non-Abusive-40.txt', 'Non-Abusive-41.txt', 'Non-Abusive-6.txt', 'Non-Abusive-7.txt', 'Non-Abusive-9.txt']\n"
     ]
    }
   ],
   "source": [
    "ffiles = []\n",
    "\n",
    "for root, dirs, files in os.walk(p):\n",
    "    for file in files:\n",
    "        # check if the file name contains the word 'hello'\n",
    "        # add the file name to the list\n",
    "        ffiles.append(file)\n",
    "            \n",
    "print(ffiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Co/Sem7/Prj/MiniProj/Dataset/TRAIN/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abusive-10.txt', 'Abusive-12.txt', 'Abusive-13.txt', 'Abusive-15.txt', 'Abusive-16.txt', 'Abusive-17.txt', 'Abusive-18.txt', 'Abusive-2.txt', 'Abusive-20.txt', 'Abusive-21.txt', 'Abusive-22.txt', 'Abusive-24.txt', 'Abusive-25.txt', 'Abusive-26.txt', 'Abusive-27.txt', 'Abusive-29.txt', 'Abusive-3.txt', 'Abusive-30.txt', 'Abusive-31.txt', 'Abusive-32.txt', 'Abusive-33.txt', 'Abusive-34.txt', 'Abusive-36.txt', 'Abusive-37.txt', 'Abusive-38.txt', 'Abusive-39.txt', 'Abusive-4.txt', 'Abusive-40.txt', 'Abusive-41.txt', 'Abusive-42.txt', 'Abusive-43.txt', 'Abusive-44.txt', 'Abusive-45.txt', 'Abusive-46.txt', 'Abusive-47.txt', 'Abusive-5.txt', 'Abusive-7.txt', 'Abusive-9.txt', 'Non-Abusive-10.txt', 'Non-Abusive-12.txt', 'Non-Abusive-14.txt', 'Non-Abusive-15.txt', 'Non-Abusive-16.txt', 'Non-Abusive-17.txt', 'Non-Abusive-18.txt', 'Non-Abusive-2.txt', 'Non-Abusive-20.txt', 'Non-Abusive-21.txt', 'Non-Abusive-22.txt', 'Non-Abusive-24.txt', 'Non-Abusive-25.txt', 'Non-Abusive-26.txt', 'Non-Abusive-27.txt', 'Non-Abusive-29.txt', 'Non-Abusive-3.txt', 'Non-Abusive-30.txt', 'Non-Abusive-31.txt', 'Non-Abusive-33.txt', 'Non-Abusive-34.txt', 'Non-Abusive-35.txt', 'Non-Abusive-36.txt', 'Non-Abusive-37.txt', 'Non-Abusive-38.txt', 'Non-Abusive-39.txt', 'Non-Abusive-4.txt', 'Non-Abusive-40.txt', 'Non-Abusive-41.txt', 'Non-Abusive-6.txt', 'Non-Abusive-7.txt', 'Non-Abusive-9.txt']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import WindowsPath\n",
    "\n",
    "#fflies = [p + element  for element in ffiles]\n",
    "print(ffiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Text_ab = []\n",
    "Text_nab = []\n",
    "Lbl_ab = []\n",
    "Lbl_nab = []\n",
    "\n",
    "for i in range(32):\n",
    "    Text_ab.append((load_text( p + ffiles[i] ,N[0], 0)))\n",
    "    Lbl_ab.append(load_len( p + ffiles[i] ,N[0], 0))\n",
    "    \n",
    "for j in range(32,70):\n",
    "    Text_nab.append(load_text( p + ffiles[j] ,N[1], 1))\n",
    "    Lbl_nab.append(load_len( p + ffiles[j] ,N[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 70)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text = Text_nab + Text_ab\n",
    "Lbl = np.concatenate((Lbl_nab, Lbl_ab), axis = 0)\n",
    "len(Text), len(Lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[Text, Lbl], index=[\"text\", \"label\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('prj_train.csv') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\".\\prj_train.csv\")\n",
    "df_dev = pd.read_csv(\".\\prj_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 2\n",
    "\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = np.array([(preprocessing(i)).split() for i in df_train[\"comments\"]])\n",
    "#X_val = np.array([(preprocessing(i)).split() for i in df_dev[\"comments\"]])\n",
    "X_train = [(preprocessing(i)) for i in df_train[\"text\"]]\n",
    "X_val = [(preprocessing(i)) for i in df_dev[\"text\"]]\n",
    "\n",
    "Y_train = le.fit_transform(np.array(df_train[\"label\"]))\n",
    "Y_val = le.fit_transform(np.array(df_dev[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32., 38.]), array([0. , 0.5, 1. ]), <BarContainer object of 2 artists>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_train,bins=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_train,columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['இது என்ன இன்று முளைத்த சொல்லலா இல்லை நூற்றாண...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ஓல் மிகச்சாதாரணமாக வருவது கிடையாது. சில சந்த...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['இப்படி வகை துணை இல்லாமல் ஓல் போடும் நண்பனுக்...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['இதுல வந்து என்னப்பதி தப்ப பேசுறது இதெல்லாம் ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['மச்சி பிரசன்னா எப்டி மச்சி, அவன் ஆ தூ, மயிரு...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  ['இது என்ன இன்று முளைத்த சொல்லலா இல்லை நூற்றாண...\n",
       "1  ['ஓல் மிகச்சாதாரணமாக வருவது கிடையாது. சில சந்த...\n",
       "2  ['இப்படி வகை துணை இல்லாமல் ஓல் போடும் நண்பனுக்...\n",
       "3  ['இதுல வந்து என்னப்பதி தப்ப பேசுறது இதெல்லாம் ...\n",
       "4  ['மச்சி பிரசன்னா எப்டி மச்சி, அவன் ஆ தூ, மயிரு..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['இது என்ன இன்று முளைத்த சொல்லலா இல்லை நூற்றாண...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ஓல் மிகச்சாதாரணமாக வருவது கிடையாது. சில சந்த...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['இப்படி வகை துணை இல்லாமல் ஓல் போடும் நண்பனுக்...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['இதுல வந்து என்னப்பதி தப்ப பேசுறது இதெல்லாம் ...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['மச்சி பிரசன்னா எப்டி மச்சி, அவன் ஆ தூ, மயிரு...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  ['இது என்ன இன்று முளைத்த சொல்லலா இல்லை நூற்றாண...  [0, 1]\n",
       "1  ['ஓல் மிகச்சாதாரணமாக வருவது கிடையாது. சில சந்த...  [0, 1]\n",
       "2  ['இப்படி வகை துணை இல்லாமல் ஓல் போடும் நண்பனுக்...  [0, 1]\n",
       "3  ['இதுல வந்து என்னப்பதி தப்ப பேசுறது இதெல்லாம் ...  [0, 1]\n",
       "4  ['மச்சி பிரசன்னா எப்டி மச்சி, அவன் ஆ தூ, மயிரு...  [0, 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"labels\"] = categorical_vals(le.transform(df_train[\"label\"]))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"class\"],df[\"comments\"] = df[\"comments\"],df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>['கார்பொரேட் கல்ச்சர் ரெண்டு டன் லடோம் அதே தாங...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>['என்ன பாதுகா ஒரு பொண்ணு வேணுமா இல்லையா இந்த ந...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>['இவங்க பெத்தவங்க பெத்தவங்க னு சொல்றாங்களே நண்...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>['இப்படி கண்ட கண்ட பாடலை அட்வைஸ் பண்ணாலும் கடை...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>['நாம் அனைவரும் வாழ்த்த பிறந்தவர்கள் வாழ்க்கைய...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  labels\n",
       "65  ['கார்பொரேட் கல்ச்சர் ரெண்டு டன் லடோம் அதே தாங...  [1, 0]\n",
       "66  ['என்ன பாதுகா ஒரு பொண்ணு வேணுமா இல்லையா இந்த ந...  [1, 0]\n",
       "67  ['இவங்க பெத்தவங்க பெத்தவங்க னு சொல்றாங்களே நண்...  [1, 0]\n",
       "68  ['இப்படி கண்ட கண்ட பாடலை அட்வைஸ் பண்ணாலும் கடை...  [1, 0]\n",
       "69  ['நாம் அனைவரும் வாழ்த்த பிறந்தவர்கள் வாழ்க்கைய...  [1, 0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  labels\n",
      "0  ['இப்போ ரிசெண்டஹ் சென்னைல ஒரு பர்டிகுலர் கடைக்...  [0, 1]\n",
      "1  ['நல்லதா? நாலு விஷயம் ஒன்று ஒப்ழ் இல் இருக்கிற...  [0, 1]\n",
      "2  ['தமிழ்நாட்டில் மட்டுமே தோராயமாக நானூற்றி. அறு...  [0, 1]\n",
      "3  ['லஸ்ட் ஒரு மூன்று மாசத்துல நான் கேள்விப்பட்டே...  [0, 1]\n",
      "4  ['பூமி உடைய தென் துருவத்தில் சூரியன் உதிக்கிறத...  [0, 1]\n"
     ]
    }
   ],
   "source": [
    "eval_frame = pd.DataFrame(X_val,columns=[\"text\"]) \n",
    "eval_frame['labels'] = categorical_vals(le.transform(df_dev[\"label\"]))\n",
    "print(eval_frame.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at monsoon-nlp/tamillion were not used when initializing BertForMultiLabelSequenceClassification: ['electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.embeddings.position_ids', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.6.attention.self.key.bias', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.4.intermediate.dense.weight']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at monsoon-nlp/tamillion and are newly initialized: ['encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'classifier.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'classifier.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "  1%|▏         | 1/70 [00:08<09:28,  8.24s/it]\n",
      "Epochs 0/20. Running Loss:    0.7199: 100%|██████████| 9/9 [00:45<00:00,  5.09s/it]\n",
      "Epochs 1/20. Running Loss:    1.1344: 100%|██████████| 9/9 [00:39<00:00,  4.40s/it]\n",
      "Epochs 2/20. Running Loss:    0.7974: 100%|██████████| 9/9 [00:39<00:00,  4.38s/it]\n",
      "Epochs 3/20. Running Loss:    0.6961: 100%|██████████| 9/9 [00:39<00:00,  4.35s/it]\n",
      "Epochs 4/20. Running Loss:    0.7901: 100%|██████████| 9/9 [00:40<00:00,  4.45s/it]\n",
      "Epochs 5/20. Running Loss:    0.6751: 100%|██████████| 9/9 [01:05<00:00,  7.32s/it]\n",
      "Epochs 6/20. Running Loss:    0.7762: 100%|██████████| 9/9 [01:06<00:00,  7.37s/it]\n",
      "Epochs 7/20. Running Loss:    0.7051: 100%|██████████| 9/9 [01:09<00:00,  7.73s/it]\n",
      "Epochs 8/20. Running Loss:    0.7637: 100%|██████████| 9/9 [01:06<00:00,  7.36s/it]\n",
      "Epochs 9/20. Running Loss:    0.6060: 100%|██████████| 9/9 [01:09<00:00,  7.71s/it]\n",
      "Epochs 10/20. Running Loss:    0.3859: 100%|██████████| 9/9 [01:05<00:00,  7.33s/it]\n",
      "Epochs 11/20. Running Loss:    0.4792: 100%|██████████| 9/9 [01:05<00:00,  7.31s/it]\n",
      "Epochs 12/20. Running Loss:    0.0586: 100%|██████████| 9/9 [01:10<00:00,  7.83s/it]\n",
      "Epochs 13/20. Running Loss:    0.0365: 100%|██████████| 9/9 [01:06<00:00,  7.34s/it]\n",
      "Epochs 14/20. Running Loss:    0.0233: 100%|██████████| 9/9 [01:07<00:00,  7.49s/it]\n",
      "Epochs 15/20. Running Loss:    0.0191: 100%|██████████| 9/9 [01:05<00:00,  7.33s/it]\n",
      "Epochs 16/20. Running Loss:    0.0149: 100%|██████████| 9/9 [01:07<00:00,  7.45s/it]\n",
      "Epochs 17/20. Running Loss:    0.0234: 100%|██████████| 9/9 [01:04<00:00,  7.15s/it]\n",
      "Epochs 18/20. Running Loss:    0.0128: 100%|██████████| 9/9 [01:18<00:00,  8.74s/it]\n",
      "Epochs 19/20. Running Loss:    0.0127: 100%|██████████| 9/9 [01:24<00:00,  9.36s/it]\n",
      "Epoch 20 of 20: 100%|██████████| 20/20 [24:19<00:00, 72.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "# set use_cuda=False on CPU-only platforms\n",
    "model = MultiLabelClassificationModel('bert', 'monsoon-nlp/tamillion', num_labels= 2, use_cuda=False,\n",
    "                            args={ 'reprocess_input_data': True, 'use_cached_eval_features': False, 'overwrite_output_dir': True, 'num_train_epochs': 20,})\n",
    "model.train_model(df,eval_data=eval_frame)\n",
    "print(\"trained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [00:18<05:20, 18.84s/it]\n",
      "Running Evaluation: 100%|██████████| 3/3 [00:04<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(eval_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [00:13<03:51, 13.60s/it]\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94         8\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.94      0.95      0.94        18\n",
      "weighted avg       0.95      0.94      0.94        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(backto(preds[0]),Y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  1%|▏         | 1/70 [00:17<20:10, 17.55s/it]\n",
      "Epochs 0/20. Running Loss:    0.6931: 100%|██████████| 9/9 [01:34<00:00, 10.45s/it]\n",
      "Epochs 1/20. Running Loss:    0.6914: 100%|██████████| 9/9 [01:20<00:00,  8.94s/it]\n",
      "Epochs 2/20. Running Loss:    0.6899: 100%|██████████| 9/9 [01:13<00:00,  8.14s/it]\n",
      "Epochs 3/20. Running Loss:    0.6963: 100%|██████████| 9/9 [01:23<00:00,  9.30s/it]\n",
      "Epochs 4/20. Running Loss:    0.6611: 100%|██████████| 9/9 [01:23<00:00,  9.27s/it]\n",
      "Epochs 5/20. Running Loss:    0.6368: 100%|██████████| 9/9 [01:26<00:00,  9.59s/it]\n",
      "Epochs 6/20. Running Loss:    0.6120: 100%|██████████| 9/9 [00:56<00:00,  6.22s/it]\n",
      "Epochs 7/20. Running Loss:    0.5898: 100%|██████████| 9/9 [00:43<00:00,  4.79s/it]\n",
      "Epochs 8/20. Running Loss:    0.5614: 100%|██████████| 9/9 [00:42<00:00,  4.71s/it]\n",
      "Epochs 9/20. Running Loss:    0.5439: 100%|██████████| 9/9 [00:42<00:00,  4.71s/it]\n",
      "Epochs 10/20. Running Loss:    0.5381: 100%|██████████| 9/9 [00:42<00:00,  4.77s/it]\n",
      "Epochs 11/20. Running Loss:    0.5015: 100%|██████████| 9/9 [00:44<00:00,  4.90s/it]\n",
      "Epochs 12/20. Running Loss:    0.5014: 100%|██████████| 9/9 [00:42<00:00,  4.74s/it]\n",
      "Epochs 13/20. Running Loss:    0.4746: 100%|██████████| 9/9 [00:42<00:00,  4.69s/it]\n",
      "Epochs 14/20. Running Loss:    0.4701: 100%|██████████| 9/9 [00:42<00:00,  4.71s/it]\n",
      "Epochs 15/20. Running Loss:    0.4748: 100%|██████████| 9/9 [00:42<00:00,  4.71s/it]\n",
      "Epochs 16/20. Running Loss:    0.4380: 100%|██████████| 9/9 [00:42<00:00,  4.69s/it]\n",
      "Epochs 17/20. Running Loss:    0.4490: 100%|██████████| 9/9 [00:42<00:00,  4.74s/it]\n",
      "Epochs 18/20. Running Loss:    0.4572: 100%|██████████| 9/9 [00:42<00:00,  4.77s/it]\n",
      "Epochs 19/20. Running Loss:    0.4505: 100%|██████████| 9/9 [00:42<00:00,  4.72s/it]\n",
      "Epoch 20 of 20: 100%|██████████| 20/20 [26:14<00:00, 78.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "# set use_cuda=False on CPU-only platforms\n",
    "model = MultiLabelClassificationModel('bert', 'google/muril-base-cased', num_labels= 2, use_cuda=False,\n",
    "                            args={ 'reprocess_input_data': True, 'use_cached_eval_features': False, 'overwrite_output_dir': True, 'num_train_epochs': 20,})\n",
    "model.train_model(df,eval_data=eval_frame)\n",
    "print(\"trained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [00:11<03:12, 11.30s/it]\n",
      "Running Evaluation: 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(eval_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [00:06<01:51,  6.56s/it]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         6\n",
      "           1       1.00      0.75      0.86        12\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.83      0.88      0.83        18\n",
      "weighted avg       0.89      0.83      0.84        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(backto(preds[0]),Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "14958d3aee5f1cad06795f787e54b96185c25fb40dfec723a5be941f3a531b8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
